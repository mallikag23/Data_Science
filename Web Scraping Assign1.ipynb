{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install bs4\n",
    "!pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All the Header Tags \n",
      "\n",
      "Main Page\n",
      "From today's featured article\n",
      "Did you know ...\n",
      "In the news\n",
      "On this day\n",
      "From today's featured list\n",
      "Today's featured picture\n",
      "Other areas of Wikipedia\n",
      "Wikipedia's sister projects\n",
      "Wikipedia languages\n",
      "Navigation menu\n",
      "Personal tools\n",
      "Namespaces\n",
      "Variants\n",
      "Views\n",
      "More\n",
      "Search\n",
      "Navigation\n",
      "Contribute\n",
      "Tools\n",
      "Print/export\n",
      "In other projects\n",
      "Languages\n"
     ]
    }
   ],
   "source": [
    "#1. Write a python program to display all the header tags from ‘en.wikipedia.org/wiki/Main_Page’.\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "def geturl(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    header=soup.find_all(['h1','h2','h3','h4','h5','h6'])\n",
    "    print('All the Header Tags \\n')\n",
    "    for i in header:\n",
    "        print(i.text.strip())     \n",
    "geturl('https://en.wikipedia.org/wiki/Main_Page')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Shawshank Redemption</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>(1972)</td>\n",
       "      <td>9.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Godfather: Part II</td>\n",
       "      <td>(1974)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Dark Knight</td>\n",
       "      <td>(2008)</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>12 Angry Men</td>\n",
       "      <td>(1957)</td>\n",
       "      <td>8.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Jagten</td>\n",
       "      <td>(2012)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Idi i smotri</td>\n",
       "      <td>(1985)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Singin' in the Rain</td>\n",
       "      <td>(1952)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>North by Northwest</td>\n",
       "      <td>(1959)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Eternal Sunshine of the Spotless Mind</td>\n",
       "      <td>(2004)</td>\n",
       "      <td>8.3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      Name    Year Rating\n",
       "1                 The Shawshank Redemption  (1994)    9.2\n",
       "2                            The Godfather  (1972)    9.1\n",
       "3                   The Godfather: Part II  (1974)    9.0\n",
       "4                          The Dark Knight  (2008)    9.0\n",
       "5                             12 Angry Men  (1957)    8.9\n",
       "..                                     ...     ...    ...\n",
       "96                                  Jagten  (2012)    8.3\n",
       "97                            Idi i smotri  (1985)    8.3\n",
       "98                     Singin' in the Rain  (1952)    8.3\n",
       "99                      North by Northwest  (1959)    8.3\n",
       "100  Eternal Sunshine of the Spotless Mind  (2004)    8.3\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2. Write a python program to display IMDB’s Top rated 100 movies’ data (i.e. Name, IMDB rating, Year of\n",
    "#release) and make data frame.\n",
    "\n",
    "#\"https://www.imdb.com/chart/top?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=cb6cf75a-1a51-49d1-af63-8202cfc3fb01&pf_rd_r=6QJ247G0N9NXM68DVPP0&pf_rd_s=right-4&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_ql_3\"\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "def getimdbdata(url):\n",
    "    page = requests.get(url)\n",
    "    soup = bs(page.text,'html.parser')\n",
    "    movies=[]\n",
    "    rlsyears=[]\n",
    "    ratings=[]\n",
    "    for i in soup.find_all('tbody',class_=\"lister-list\"):\n",
    "        for j in i.find_all(\"a\"): movies.append(j.text.strip())\n",
    "    for i in soup.find_all('span',class_=\"secondaryInfo\"): rlsyears.append(i.text)\n",
    "    for i in soup.find_all('td',class_=\"ratingColumn imdbRating\"): ratings.append(i.text.replace('\\n',''))\n",
    "    movies= list(filter(None, movies))\n",
    "    tops=pd.DataFrame({'Name':movies,'Year':rlsyears,'Rating':ratings})\n",
    "    tops = tops.rename(index = lambda x: x+1)\n",
    "    return tops.head(100)\n",
    "getimdbdata('https://www.imdb.com/chart/top?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=cb6cf75a-1a51-49d1-af63-8202cfc3fb01&pf_rd_r=6QJ247G0N9NXM68DVPP0&pf_rd_s=right-4&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_ql_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year</th>\n",
       "      <th>Rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Pather Panchali</td>\n",
       "      <td>(1955)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nayakan</td>\n",
       "      <td>(1987)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pariyerum Perumal</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Anbe Sivam</td>\n",
       "      <td>(2003)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Golmaal</td>\n",
       "      <td>(1979)</td>\n",
       "      <td>8.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Andaz Apna Apna</td>\n",
       "      <td>(1994)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Virumandi</td>\n",
       "      <td>(2004)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Uri: The Surgical Strike</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>PK</td>\n",
       "      <td>(2014)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Lucia</td>\n",
       "      <td>(2013)</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name    Year Rating\n",
       "1             Pather Panchali  (1955)    8.5\n",
       "2                     Nayakan  (1987)    8.5\n",
       "3           Pariyerum Perumal  (2018)    8.5\n",
       "4                  Anbe Sivam  (2003)    8.5\n",
       "5                     Golmaal  (1979)    8.5\n",
       "..                        ...     ...    ...\n",
       "96            Andaz Apna Apna  (1994)    8.1\n",
       "97                  Virumandi  (2004)    8.1\n",
       "98   Uri: The Surgical Strike  (2018)    8.1\n",
       "99                         PK  (2014)    8.1\n",
       "100                     Lucia  (2013)    8.1\n",
       "\n",
       "[100 rows x 3 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3. Write a python program to display IMDB’s Top rated 100 Indian movies’ data (i.e. Name, IMDB rating, Year \n",
    "#of release) and make data frame.\n",
    "    \n",
    "#\"https://www.imdb.com/india/top-rated-indian-movies/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=8a7876cd-2844-4017-846a-2c0876945b7b&pf_rd_r=0B4VQKBRXSZMZE916Q7R&pf_rd_s=right-5&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_india_tr_rhs_1\"\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "import pandas as pd\n",
    "def topindianmovies(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    movies=[]\n",
    "    rlsyears=[]\n",
    "    ratings=[]\n",
    "    for i in soup.find_all('tbody',class_=\"lister-list\"):\n",
    "        for j in i.find_all(\"a\"): movies.append(j.text.strip())\n",
    "    for i in soup.find_all('span',class_=\"secondaryInfo\"): rlsyears.append(i.text)\n",
    "    for i in soup.find_all('td',class_=\"ratingColumn imdbRating\"): ratings.append(i.text.replace('\\n',''))\n",
    "    movies= list(filter(None, movies))\n",
    "    tops=pd.DataFrame({'Name':movies,'Year':rlsyears,'Rating':ratings})\n",
    "    tops = tops.rename(index = lambda x: x+1)\n",
    "    return tops.head(100)    \n",
    "topindianmovies('https://www.imdb.com/india/top-rated-indian-movies/?pf_rd_m=A2FGELUUNOQJNL&pf_rd_p=8a7876cd-2844-4017-846a-2c0876945b7b&pf_rd_r=0B4VQKBRXSZMZE916Q7R&pf_rd_s=right-5&pf_rd_t=15506&pf_rd_i=top&ref_=chttp_india_tr_rhs_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book_Name</th>\n",
       "      <th>Author_Name</th>\n",
       "      <th>Genre_Name</th>\n",
       "      <th>Book_Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Woman They Could Not Silence</td>\n",
       "      <td>Kate Moore</td>\n",
       "      <td>Nonfiction / History / Women's History</td>\n",
       "      <td>In the 19th century, a brave, brilliant and co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Under a Dancing Star</td>\n",
       "      <td>Laura Wood</td>\n",
       "      <td>YA / YA Fiction</td>\n",
       "      <td>Under a Dancing Star is an effervescent retell...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yoke</td>\n",
       "      <td>Jessamyn Stanley</td>\n",
       "      <td>Nonfiction / Essays / Body, Mind &amp; Spirit</td>\n",
       "      <td>The 13 autobiographical essays in Yoke are bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leaving Isn’t the Hardest Thing</td>\n",
       "      <td>Lauren Hough, Cate Blanchett</td>\n",
       "      <td>Audio / Nonfiction / Essays</td>\n",
       "      <td>Author Lauren Hough and actor-producer Cate Bl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The Rose Code</td>\n",
       "      <td>Kate Quinn, Saskia Maarleveld</td>\n",
       "      <td>Audio / Fiction / Historical Fiction</td>\n",
       "      <td>The Rose Code is a terrific story, brilliantly...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          Book_Name                    Author_Name  \\\n",
       "1  The Woman They Could Not Silence                     Kate Moore   \n",
       "2              Under a Dancing Star                     Laura Wood   \n",
       "3                              Yoke               Jessamyn Stanley   \n",
       "4   Leaving Isn’t the Hardest Thing   Lauren Hough, Cate Blanchett   \n",
       "5                     The Rose Code  Kate Quinn, Saskia Maarleveld   \n",
       "\n",
       "                                  Genre_Name  \\\n",
       "1     Nonfiction / History / Women's History   \n",
       "2                            YA / YA Fiction   \n",
       "3  Nonfiction / Essays / Body, Mind & Spirit   \n",
       "4                Audio / Nonfiction / Essays   \n",
       "5       Audio / Fiction / Historical Fiction   \n",
       "\n",
       "                                        Book_Reviews  \n",
       "1  In the 19th century, a brave, brilliant and co...  \n",
       "2  Under a Dancing Star is an effervescent retell...  \n",
       "3  The 13 autobiographical essays in Yoke are bra...  \n",
       "4  Author Lauren Hough and actor-producer Cate Bl...  \n",
       "5  The Rose Code is a terrific story, brilliantly...  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4. Write a python program to scrap book name, author name, genre and book review of any 5 books from\n",
    "#‘www.bookpage.com’\n",
    "\n",
    "#\"https://bookpage.com/reviews\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "def bookinfo(url):    \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    bnames=[]\n",
    "    nauthors=[]\n",
    "    genres=[] \n",
    "    breviews=[] \n",
    "    for i in soup.find_all('h4',class_=\"italic\"):bnames.append(i.text.replace('\\n',''))\n",
    "    for i in soup.find_all('p',class_=\"sans bold\"):nauthors.append(i.text.replace('\\n',''))\n",
    "    for i in soup.find_all('p',class_=\"genre-links hidden-phone\"): genres.append(i.text.replace('\\n',''))\n",
    "    for i in soup.find_all('p',class_=\"excerpt\"): breviews.append(i.text.replace('\\n',''))\n",
    "    bdetails = pd.DataFrame({})\n",
    "    bdetails['Book_Name']=bnames\n",
    "    bdetails['Author_Name']=nauthors \n",
    "    bdetails['Genre_Name']=genres\n",
    "    bdetails['Book_Reviews']=breviews\n",
    "    bdetails = bdetails.rename(index = lambda x: x+1)\n",
    "    return bdetails.head(5)\n",
    "bookinfo('https://bookpage.com/reviews')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Match</th>\n",
       "      <th>Point</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>17</td>\n",
       "      <td>2,054</td>\n",
       "      <td>121               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>India</td>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>England</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>27</td>\n",
       "      <td>27</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country Match  Point  \\\n",
       "1    New Zealand    17  2,054   \n",
       "2      Australia    25     25   \n",
       "3          India    29     29   \n",
       "4        England    27     27   \n",
       "5   South Africa    20     20   \n",
       "6       Pakistan    24     24   \n",
       "7     Bangladesh    27     27   \n",
       "8    West Indies    27     27   \n",
       "9      Sri Lanka    24     24   \n",
       "10   Afghanistan    17     17   \n",
       "\n",
       "                                              Ranking  \n",
       "1                               121               ...  \n",
       "2                                                 118  \n",
       "3                                                 115  \n",
       "4                                                 115  \n",
       "5                                                 107  \n",
       "6                                                  97  \n",
       "7                                                  90  \n",
       "8                                                  82  \n",
       "9                                                  78  \n",
       "10                                                 62  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "#i) Top 10 ODI teams in men’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "#\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "url=\"https://www.icc-cricket.com/rankings/mens/team-rankings/odi\"\n",
    "def modiinfo(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    modis=[]\n",
    "    matchs=[]\n",
    "    points=[]\n",
    "    ranks=[]\n",
    "    for i in soup.find_all('span',class_=\"u-hide-phablet\"):modis.append(i.text)\n",
    "    modis= list(filter(None, modis))\n",
    "    bmatch=[]\n",
    "    for i in soup.find_all('td',class_=\"rankings-block__banner--matches\"): bmatch.append(i.text)   \n",
    "    for i in soup.find_all('td',class_=\"table-body__cell u-center-text\") : matchs.append(i.text)\n",
    "    nmatchs=[matchs[i] for i in range(0,len(matchs),2)]\n",
    "    Amatchs=bmatch+nmatchs\n",
    "    bpoint=[]\n",
    "    for i in soup.find_all('td',class_=\"rankings-block__banner--points\"): bpoint.append(i.text)\n",
    "    for i in soup.find_all('td',class_=\"table-body__cell u-center-text\"):points.append(i.text)\n",
    "    npoints=[points[i] for i in range(0,len(points),2)]\n",
    "    Apoints=bpoint+npoints\n",
    "    for i in soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):ranks.append(i.text.replace(\"\\n\",''))\n",
    "    for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):ranks.append(i.text)\n",
    "    odis = pd.DataFrame({'Country':modis,'Match':Amatchs,'Point':Apoints,'Ranking':ranks})\n",
    "    odis = odis.rename(index = lambda x: x+1)\n",
    "    return odis.head(10)\n",
    "modiinfo('https://www.icc-cricket.com/rankings/mens/team-rankings/odi')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>nationality</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Babar Azam</td>\n",
       "      <td>PAK</td>\n",
       "      <td>865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Virat Kohli</td>\n",
       "      <td>IND</td>\n",
       "      <td>857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rohit Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ross Taylor</td>\n",
       "      <td>NZ</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aaron Finch</td>\n",
       "      <td>AUS</td>\n",
       "      <td>791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jonny Bairstow</td>\n",
       "      <td>ENG</td>\n",
       "      <td>785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Fakhar Zaman</td>\n",
       "      <td>PAK</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Francois du Plessis</td>\n",
       "      <td>SA</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>David Warner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Shai Hope</td>\n",
       "      <td>WI</td>\n",
       "      <td>773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 player nationality Ranking\n",
       "1            Babar Azam         PAK     865\n",
       "2           Virat Kohli         IND     857\n",
       "3          Rohit Sharma         IND     825\n",
       "4           Ross Taylor          NZ     801\n",
       "5           Aaron Finch         AUS     791\n",
       "6        Jonny Bairstow         ENG     785\n",
       "7          Fakhar Zaman         PAK     778\n",
       "8   Francois du Plessis          SA     778\n",
       "9          David Warner         AUS     773\n",
       "10            Shai Hope          WI     773"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ii) Top 10 ODI Batsmen in men along with the records of their team and rating.\n",
    "\n",
    "#\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "def odibatsmeninfo(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    mplayer=[]\n",
    "    mnation=[]\n",
    "    mranks=[]\n",
    "    for i in soup.find_all('div',class_=\"rankings-block__banner--name-large\"): mplayer.append(i.text) \n",
    "    for i in soup.find_all('div',class_=\"rankings-block__banner--nationality\"): mnation.append(i.text.replace('\\n','')) \n",
    "    for i in soup.find_all('div',class_=\"rankings-block__banner--rating\"): mranks.append(i.text)\n",
    "    for i in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "        for j in i.find_all(\"a\"): mplayer.append(j.text.strip())\n",
    "    for i in soup.find_all('span',class_=\"table-body__logo-text\"): mnation.append(i.text.replace('\\n',''))\n",
    "    for i in soup.find_all('td',class_=\"table-body__cell rating\"): mranks.append(i.text)\n",
    "    modis = pd.DataFrame({'player':mplayer,'nationality':mnation,'Ranking':mranks})\n",
    "    modis = modis.rename(index = lambda x: x+1)\n",
    "    return modis.head(10)\n",
    "odibatsmeninfo('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/batting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Player</th>\n",
       "      <th>Nationality</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Trent Boult</td>\n",
       "      <td>NZ</td>\n",
       "      <td>737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mehedi Hasan</td>\n",
       "      <td>BAN</td>\n",
       "      <td>713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mujeeb Ur Rahman</td>\n",
       "      <td>AFG</td>\n",
       "      <td>708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Matt Henry</td>\n",
       "      <td>NZ</td>\n",
       "      <td>691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Jasprit Bumrah</td>\n",
       "      <td>IND</td>\n",
       "      <td>690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Kagiso Rabada</td>\n",
       "      <td>SA</td>\n",
       "      <td>666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Chris Woakes</td>\n",
       "      <td>ENG</td>\n",
       "      <td>665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Josh Hazlewood</td>\n",
       "      <td>AUS</td>\n",
       "      <td>660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Pat Cummins</td>\n",
       "      <td>AUS</td>\n",
       "      <td>646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mustafizur Rahman</td>\n",
       "      <td>BAN</td>\n",
       "      <td>645</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Player Nationality Ranking\n",
       "1         Trent Boult          NZ     737\n",
       "2        Mehedi Hasan         BAN     713\n",
       "3    Mujeeb Ur Rahman         AFG     708\n",
       "4          Matt Henry          NZ     691\n",
       "5      Jasprit Bumrah         IND     690\n",
       "6       Kagiso Rabada          SA     666\n",
       "7        Chris Woakes         ENG     665\n",
       "8      Josh Hazlewood         AUS     660\n",
       "9         Pat Cummins         AUS     646\n",
       "10  Mustafizur Rahman         BAN     645"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iii) Top 10 ODI bowlers along with the records of their team and rating.\n",
    "\n",
    "#\"https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling\"\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "def odibowlerinfo(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    mplayer=[]\n",
    "    mnation=[]\n",
    "    mranks=[]\n",
    "    for i in soup.find_all('div',class_=\"rankings-block__banner--name-large\"): mplayer.append(i.text) \n",
    "    for i in soup.find_all('div',class_=\"rankings-block__banner--nationality\"): mnation.append(i.text.replace('\\n','')) \n",
    "    for i in soup.find_all('div',class_=\"rankings-block__banner--rating\"): mranks.append(i.text) \n",
    "    for i in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "        for j in i.find_all(\"a\"): mplayer.append(j.text.strip())\n",
    "    for i in soup.find_all('span',class_=\"table-body__logo-text\"): mnation.append(i.text.replace('\\n',''))\n",
    "    for i in soup.find_all('td',class_=\"table-body__cell rating\"): mranks.append(i.text)\n",
    "    modis = pd.DataFrame({'Player':mplayer,'Nationality':mnation,'Ranking':mranks})\n",
    "    modis = modis.rename(index = lambda x: x+1)\n",
    "    return modis.head(10)\n",
    "odibowlerinfo('https://www.icc-cricket.com/rankings/mens/player-rankings/odi/bowling')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Country</th>\n",
       "      <th>Match</th>\n",
       "      <th>Point</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>18</td>\n",
       "      <td>2,955</td>\n",
       "      <td>164               ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>South Africa</td>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>England</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>India</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>West Indies</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Pakistan</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Bangladesh</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sri Lanka</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         Country Match  Point  \\\n",
       "1      Australia    18  2,955   \n",
       "2   South Africa    24     24   \n",
       "3        England    17     17   \n",
       "4          India    20     20   \n",
       "5    New Zealand    21     21   \n",
       "6    West Indies    12     12   \n",
       "7       Pakistan    15     15   \n",
       "8     Bangladesh     5      5   \n",
       "9      Sri Lanka    11     11   \n",
       "10       Ireland     2      2   \n",
       "\n",
       "                                              Ranking  \n",
       "1                               164               ...  \n",
       "2                                                 118  \n",
       "3                                                 117  \n",
       "4                                                 111  \n",
       "5                                                  93  \n",
       "6                                                  85  \n",
       "7                                                  73  \n",
       "8                                                  61  \n",
       "9                                                  47  \n",
       "10                                                 13  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6. Write a python program to scrape cricket rankings from ‘www.icc-cricket.com’. You have to scrape:\n",
    "#i) Top 10 ODI teams in women’s cricket along with the records for matches, points and rating.\n",
    "\n",
    "#https://www.icc-cricket.com/rankings/womens/team-rankings/odi\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd    \n",
    "def wodiinfo(url):   \n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    wmodis=[]\n",
    "    wmatchs=[]\n",
    "    wpoints=[]\n",
    "    wranks=[]\n",
    "    for i in soup.find_all('span',class_=\"u-hide-phablet\"):wmodis.append(i.text)\n",
    "    wmodis= list(filter(None, wmodis))\n",
    "    bmatch=[]\n",
    "    for i in soup.find_all('td',class_=\"rankings-block__banner--matches\"): bmatch.append(i.text)   \n",
    "    for i in soup.find_all('td',class_=\"table-body__cell u-center-text\") : wmatchs.append(i.text)\n",
    "    nmatchs=[wmatchs[i] for i in range(0,len(wmatchs),2)]\n",
    "    Amatchs=bmatch+nmatchs\n",
    "    bpoint=[]\n",
    "    for i in soup.find_all('td',class_=\"rankings-block__banner--points\"): bpoint.append(i.text)\n",
    "    for i in soup.find_all('td',class_=\"table-body__cell u-center-text\"):wpoints.append(i.text)\n",
    "    npoints=[wpoints[i] for i in range(0,len(wpoints),2)]\n",
    "    Apoints=bpoint+npoints\n",
    "    for i in soup.find_all('td',class_=\"rankings-block__banner--rating u-text-right\"):wranks.append(i.text.replace(\"\\n\",''))\n",
    "    for i in soup.find_all('td',class_=\"table-body__cell u-text-right rating\"):wranks.append(i.text)\n",
    "    wodis = pd.DataFrame({'Country':wmodis,'Match':Amatchs,'Point':Apoints,'Ranking':wranks})\n",
    "    wodis = wodis.rename(index = lambda x: x+1)\n",
    "    return wodis.head(10)\n",
    "wodiinfo('https://www.icc-cricket.com/rankings/womens/team-rankings/odi') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>nationality</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Tammy Beaumont</td>\n",
       "      <td>ENG</td>\n",
       "      <td>765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Lizelle Lee</td>\n",
       "      <td>SA</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Alyssa Healy</td>\n",
       "      <td>AUS</td>\n",
       "      <td>756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Meg Lanning</td>\n",
       "      <td>AUS</td>\n",
       "      <td>723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Amy Satterthwaite</td>\n",
       "      <td>NZ</td>\n",
       "      <td>715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Smriti Mandhana</td>\n",
       "      <td>IND</td>\n",
       "      <td>710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mithali Raj</td>\n",
       "      <td>IND</td>\n",
       "      <td>709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Laura Wolvaardt</td>\n",
       "      <td>SA</td>\n",
       "      <td>683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               player nationality Ranking\n",
       "1      Tammy Beaumont         ENG     765\n",
       "2         Lizelle Lee          SA     758\n",
       "3        Alyssa Healy         AUS     756\n",
       "4     Stafanie Taylor          WI     746\n",
       "5         Meg Lanning         AUS     723\n",
       "6   Amy Satterthwaite          NZ     715\n",
       "7     Smriti Mandhana         IND     710\n",
       "8         Mithali Raj         IND     709\n",
       "9      Natalie Sciver         ENG     685\n",
       "10    Laura Wolvaardt          SA     683"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#ii) Top 10 women’s ODI players along with the records of their team and rating.\n",
    "\n",
    "#https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "def woditeam(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    wplayer=[]\n",
    "    wnation=[]\n",
    "    wranks=[]\n",
    "    for i in soup.find_all('div',class_=\"rankings-block__banner--name-large\"): wplayer.append(i.text) \n",
    "    for i in soup.find_all('div',class_=\"rankings-block__banner--nationality\"): wnation.append(i.text.replace('\\n','')) \n",
    "    for i in soup.find_all('div',class_=\"rankings-block__banner--rating\"): wranks.append(i.text) \n",
    "    for i in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "        for j in i.find_all(\"a\"): wplayer.append(j.text.strip())\n",
    "    for i in soup.find_all('span',class_=\"table-body__logo-text\"): wnation.append(i.text.replace('\\n',''))\n",
    "    for i in soup.find_all('td',class_=\"table-body__cell rating\"): wranks.append(i.text)\n",
    "    wodis = pd.DataFrame({'player':wplayer,'nationality':wnation,'Ranking':wranks})\n",
    "    wodis = wodis.rename(index = lambda x: x+1)\n",
    "    return wodis.head(10)\n",
    "woditeam('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/batting')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>player</th>\n",
       "      <th>nationality</th>\n",
       "      <th>Ranking</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Marizanne Kapp</td>\n",
       "      <td>SA</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ellyse Perry</td>\n",
       "      <td>AUS</td>\n",
       "      <td>418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stafanie Taylor</td>\n",
       "      <td>WI</td>\n",
       "      <td>410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Natalie Sciver</td>\n",
       "      <td>ENG</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Deepti Sharma</td>\n",
       "      <td>IND</td>\n",
       "      <td>343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jess Jonassen</td>\n",
       "      <td>AUS</td>\n",
       "      <td>307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ashleigh Gardner</td>\n",
       "      <td>AUS</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Dane van Niekerk</td>\n",
       "      <td>SA</td>\n",
       "      <td>243</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Sophie Devine</td>\n",
       "      <td>NZ</td>\n",
       "      <td>242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Amelia Kerr</td>\n",
       "      <td>NZ</td>\n",
       "      <td>236</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              player nationality Ranking\n",
       "1     Marizanne Kapp          SA     418\n",
       "2       Ellyse Perry         AUS     418\n",
       "3    Stafanie Taylor          WI     410\n",
       "4     Natalie Sciver         ENG     349\n",
       "5      Deepti Sharma         IND     343\n",
       "6      Jess Jonassen         AUS     307\n",
       "7   Ashleigh Gardner         AUS     252\n",
       "8   Dane van Niekerk          SA     243\n",
       "9      Sophie Devine          NZ     242\n",
       "10       Amelia Kerr          NZ     236"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#iii) Top 10 women’s ODI all-rounder along with the records of their team and rating.\n",
    "\n",
    "#https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "def wodiallrounder(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    wplayer=[]\n",
    "    wnation=[]\n",
    "    wranks=[]\n",
    "    for i in soup.find_all('div',class_=\"rankings-block__banner--name-large\"): wplayer.append(i.text) \n",
    "    for i in soup.find_all('div',class_=\"rankings-block__banner--nationality\"): wnation.append(i.text.replace('\\n','')) \n",
    "    for i in soup.find_all('div',class_=\"rankings-block__banner--rating\"): wranks.append(i.text) \n",
    "    for i in soup.find_all('td',class_=\"table-body__cell rankings-table__name name\"):\n",
    "        for j in i.find_all(\"a\"): wplayer.append(j.text.strip())\n",
    "    for i in soup.find_all('span',class_=\"table-body__logo-text\"): wnation.append(i.text.replace('\\n',''))\n",
    "    for i in soup.find_all('td',class_=\"table-body__cell rating\"): wranks.append(i.text)    \n",
    "    wodis = pd.DataFrame({'player':wplayer,'nationality':wnation,'Ranking':wranks})\n",
    "    wodis = wodis.rename(index = lambda x: x+1)\n",
    "    return wodis.head(10)    \n",
    "wodiallrounder('https://www.icc-cricket.com/rankings/womens/player-rankings/odi/all-rounder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Empty List\n",
    "\n",
    "\n",
    "#7. Write a python program to scrape details of all the mobile phones under Rs. 20,000 listed on Amazon.in. The \n",
    "#scraped data should include Product Name, Price, Image URL and Average Rating.\n",
    "\n",
    "\n",
    "#https://www.amazon.in/s?bbn=1389401031&rh=n%3A1389401031%2Cp_36%3A1318506031&dc&qid=1624119293&rnid=1318502031&ref=lp_1389401031_nr_p_36_3\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "def mobileinfo(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    pnames=[]\n",
    "    prices=[]\n",
    "    imageurls=[] \n",
    "    avgratings=[] \n",
    "    for i in soup.find_all('span',class_=\"a-size-base-plus a-color-base a-text-normal\"):pnames.append(i.text)\n",
    "    for i in soup.find_all('span',class_=\"a-price-whole\"):prices.append(i.text)\n",
    "    for i in soup.find_all('div',class_=\"s-image\"):imageurls.append(i.text) \n",
    "    for i in soup.find_all('span',class_=\"a-size-base\"):avgratings.append(i.text)\n",
    "    pdetails = pd.DataFrame({'Product Name':pnames,'Price':prices,'Image Link':imageurls,'Rating':avgratings})\n",
    "    pdetails = pdetails.rename(index = lambda x: x+1)\n",
    "    return pdetails\n",
    "mobileinfo('https://www.amazon.in/s?bbn=1389401031&rh=n%3A1389401031%2Cp_36%3A1318506031&dc&qid=1624119293&rnid=1318502031&ref=lp_1389401031_nr_p_36_3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Days</th>\n",
       "      <th>Short_Description</th>\n",
       "      <th>Description</th>\n",
       "      <th>Temperature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Today</td>\n",
       "      <td>Partly Sunnythen Sunnyand Breezy</td>\n",
       "      <td>Mostly cloudy, then gradually becoming sunny, ...</td>\n",
       "      <td>High: 69 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tonight</td>\n",
       "      <td>IncreasingClouds</td>\n",
       "      <td>Increasing clouds, with a low around 59. South...</td>\n",
       "      <td>Low: 59 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>DecreasingClouds</td>\n",
       "      <td>Mostly cloudy, then gradually becoming sunny, ...</td>\n",
       "      <td>High: 70 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tuesday Night</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>Partly cloudy, with a low around 58. Southwest...</td>\n",
       "      <td>Low: 58 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Sunny, with a high near 69. West southwest win...</td>\n",
       "      <td>High: 69 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wednesday Night</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>Partly cloudy, with a low around 56.</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Thursday</td>\n",
       "      <td>Sunny</td>\n",
       "      <td>Sunny, with a high near 68.</td>\n",
       "      <td>High: 68 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Thursday Night</td>\n",
       "      <td>Partly Cloudy</td>\n",
       "      <td>Partly cloudy, with a low around 56.</td>\n",
       "      <td>Low: 56 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Friday</td>\n",
       "      <td>Mostly Sunny</td>\n",
       "      <td>Mostly sunny, with a high near 69.</td>\n",
       "      <td>High: 69 °F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Friday Night</td>\n",
       "      <td>-</td>\n",
       "      <td>Partly cloudy, with a low around 57.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Saturday</td>\n",
       "      <td>-</td>\n",
       "      <td>Sunny, with a high near 72.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Saturday Night</td>\n",
       "      <td>-</td>\n",
       "      <td>Partly cloudy, with a low around 57.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Sunday</td>\n",
       "      <td>-</td>\n",
       "      <td>Sunny, with a high near 74.</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Days                 Short_Description  \\\n",
       "1             Today  Partly Sunnythen Sunnyand Breezy   \n",
       "2           Tonight                  IncreasingClouds   \n",
       "3           Tuesday                  DecreasingClouds   \n",
       "4     Tuesday Night                     Partly Cloudy   \n",
       "5         Wednesday                             Sunny   \n",
       "6   Wednesday Night                     Partly Cloudy   \n",
       "7          Thursday                             Sunny   \n",
       "8    Thursday Night                     Partly Cloudy   \n",
       "9            Friday                      Mostly Sunny   \n",
       "10     Friday Night                                 -   \n",
       "11         Saturday                                 -   \n",
       "12   Saturday Night                                 -   \n",
       "13           Sunday                                 -   \n",
       "\n",
       "                                          Description  Temperature  \n",
       "1   Mostly cloudy, then gradually becoming sunny, ...  High: 69 °F  \n",
       "2   Increasing clouds, with a low around 59. South...   Low: 59 °F  \n",
       "3   Mostly cloudy, then gradually becoming sunny, ...  High: 70 °F  \n",
       "4   Partly cloudy, with a low around 58. Southwest...   Low: 58 °F  \n",
       "5   Sunny, with a high near 69. West southwest win...  High: 69 °F  \n",
       "6                Partly cloudy, with a low around 56.   Low: 56 °F  \n",
       "7                         Sunny, with a high near 68.  High: 68 °F  \n",
       "8                Partly cloudy, with a low around 56.   Low: 56 °F  \n",
       "9                  Mostly sunny, with a high near 69.  High: 69 °F  \n",
       "10               Partly cloudy, with a low around 57.            -  \n",
       "11                        Sunny, with a high near 72.            -  \n",
       "12               Partly cloudy, with a low around 57.            -  \n",
       "13                        Sunny, with a high near 74.            -  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8. Write a python program to extract information about the local weather from the National Weather Service \n",
    "#website of USA, https://www.weather.gov/ for the city, San Francisco. You need to extract data about 7 day \n",
    "#extended forecast display for the city. The data should include period, short description, temperature and \n",
    "#description.\n",
    "\n",
    "#https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YM2UHfLivIV\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "def weatherinfo(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    periods=[]\n",
    "    sdescts=[]\n",
    "    temps=[]\n",
    "    descts=[]\n",
    "    Addsp=['-','-','-','-']\n",
    "    for i in soup.find_all('div',class_=\"col-sm-2 forecast-label\"): periods.append(i.text)    \n",
    "    for i in soup.find_all('p',class_=\"short-desc\"): sdescts.append(i.text)\n",
    "    ssdescts=sdescts+Addsp    \n",
    "    for i in soup.find_all('p',class_=\"temp\"): temps.append(i.text)\n",
    "    stemps=temps+Addsp \n",
    "    for i in soup.find_all('div',class_=\"col-sm-10 forecast-text\"): descts.append(i.text)    \n",
    "    tdetail = pd.DataFrame({'Days':periods,'Short_Description':ssdescts,'Description':descts,'Temperature':stemps})\n",
    "    tdetail = tdetail.rename(index = lambda x: x+1)   \n",
    "    return tdetail   \n",
    "weatherinfo('https://forecast.weather.gov/MapClick.php?lat=37.777120000000025&lon=-122.41963999999996#.YM2UHfLivIV')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_Title</th>\n",
       "      <th>Company_Names</th>\n",
       "      <th>CTC</th>\n",
       "      <th>Apply_Date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Administration Associate</td>\n",
       "      <td>Global Sun</td>\n",
       "      <td>3 - 3.2 LPA</td>\n",
       "      <td>21 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recruiter</td>\n",
       "      <td>Radish Consultants Private Limited</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>21 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>Medico Healthcare Services &amp; Technologies</td>\n",
       "      <td>3 - 3.2 LPA</td>\n",
       "      <td>21 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Project Coordinator</td>\n",
       "      <td>Edupixels</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>21 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Web Developer</td>\n",
       "      <td>Manufac Analytics Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>19 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Software Engineer Trainee</td>\n",
       "      <td>Swabhav Techlabs</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>19 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Business Development Specialist (Sales &amp; Marke...</td>\n",
       "      <td>Claraeon Learning Private Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>19 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Picostone</td>\n",
       "      <td>3 - 6.5 LPA</td>\n",
       "      <td>19 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Associate Front End Developer</td>\n",
       "      <td>AIMonk Labs Technology Limited</td>\n",
       "      <td>6 - 7 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Corporate Sales Executive</td>\n",
       "      <td>369 Zoss Waters</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Associate Software Developer (Full-Stack - Rea...</td>\n",
       "      <td>SleekSky LLC</td>\n",
       "      <td>4 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Customer Relationship Specialist</td>\n",
       "      <td>InPhase Power Technologies</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Associate Editor Engagement</td>\n",
       "      <td>Cactus Communications Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Management Consultant Associate</td>\n",
       "      <td>StrategyCo.Global</td>\n",
       "      <td>4.5 - 7 LPA</td>\n",
       "      <td>18 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Web Analytics Developer</td>\n",
       "      <td>DataVinci Private Limited</td>\n",
       "      <td>4.99 - 5 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Junior Social Media Marketing Manager</td>\n",
       "      <td>The Test Tribe</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Junior Social Media Marketing Associate</td>\n",
       "      <td>Glu Studios</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Business Development Manager (Digital Marketin...</td>\n",
       "      <td>Graygraph Technologies LLC</td>\n",
       "      <td>3 - 4.5 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>BookLeaf Publishing</td>\n",
       "      <td>3 - 3.6 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Accountant</td>\n",
       "      <td>Ravi Ladia &amp; Co</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Research Associate</td>\n",
       "      <td>Market Vistas Consumer Insights</td>\n",
       "      <td>3 - 3.25 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Assistant Coordinator - Tender Department</td>\n",
       "      <td>Global Source Trading LLC</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Customer Relationship Manager (Publishing Cons...</td>\n",
       "      <td>Blue Rose Publishers</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Executive Assistant To Director</td>\n",
       "      <td>Best Roadways Limited</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>17 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Learning Consultant - Sales</td>\n",
       "      <td>Geekster</td>\n",
       "      <td>3 - 3.5 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>School/Teacher Consultant</td>\n",
       "      <td>InfyBytes AI Labs Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>16 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Software Developer</td>\n",
       "      <td>Moxie.xyz</td>\n",
       "      <td>9 LPA</td>\n",
       "      <td>15 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Business Development Executive (Inside Sales)</td>\n",
       "      <td>GREedge</td>\n",
       "      <td>3.75 LPA</td>\n",
       "      <td>15 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Web Developer</td>\n",
       "      <td>Fullmoon Outdoor Web Solutions</td>\n",
       "      <td>4 - 4.2 LPA</td>\n",
       "      <td>15 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Order Processor</td>\n",
       "      <td>InspectHOA</td>\n",
       "      <td>3 LPA</td>\n",
       "      <td>14 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>Nikulsan Technologies Private Limited</td>\n",
       "      <td>3.5 - 5 LPA</td>\n",
       "      <td>14 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Associate Software Developer</td>\n",
       "      <td>IQGateway</td>\n",
       "      <td>3.6 - 10 LPA</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Reactjs Developer</td>\n",
       "      <td>Startxlabs Technologies Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Full Stack Developer</td>\n",
       "      <td>RavGins International Private Limited (Wobb.ai)</td>\n",
       "      <td>3.3 - 4 LPA</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Business Development Executive</td>\n",
       "      <td>Varenyam Placements</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Corporate Sales Associate</td>\n",
       "      <td>HealthPlix Technologies Private Limited</td>\n",
       "      <td>3 - 4 LPA</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Inside Sales Associate</td>\n",
       "      <td>Wizklub Learning</td>\n",
       "      <td>3 - 6 LPA</td>\n",
       "      <td>11 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Mobile App Developer</td>\n",
       "      <td>Fusion Engineering</td>\n",
       "      <td>4.5 - 5.25 LPA</td>\n",
       "      <td>14 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Junior MERN Stack Developer</td>\n",
       "      <td>DeepThought Edutech Ventures Private Limited</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>15 Jul' 21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>Education Innovation Manager</td>\n",
       "      <td>DeepThought Edutech Ventures Private Limited</td>\n",
       "      <td>3 - 5 LPA</td>\n",
       "      <td>10 Jul' 21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Job_Title  \\\n",
       "1                           Administration Associate    \n",
       "2                                          Recruiter    \n",
       "3                       Associate Software Developer    \n",
       "4                                Project Coordinator    \n",
       "5                                      Web Developer    \n",
       "6                          Software Engineer Trainee    \n",
       "7   Business Development Specialist (Sales & Marke...   \n",
       "8                     Business Development Executive    \n",
       "9                      Associate Front End Developer    \n",
       "10                         Corporate Sales Executive    \n",
       "11  Associate Software Developer (Full-Stack - Rea...   \n",
       "12                  Customer Relationship Specialist    \n",
       "13                       Associate Editor Engagement    \n",
       "14                   Management Consultant Associate    \n",
       "15                           Web Analytics Developer    \n",
       "16             Junior Social Media Marketing Manager    \n",
       "17           Junior Social Media Marketing Associate    \n",
       "18  Business Development Manager (Digital Marketin...   \n",
       "19                    Business Development Executive    \n",
       "20                                        Accountant    \n",
       "21                                Research Associate    \n",
       "22         Assistant Coordinator - Tender Department    \n",
       "23  Customer Relationship Manager (Publishing Cons...   \n",
       "24                   Executive Assistant To Director    \n",
       "25                       Learning Consultant - Sales    \n",
       "26                         School/Teacher Consultant    \n",
       "27                                Software Developer    \n",
       "28     Business Development Executive (Inside Sales)    \n",
       "29                                     Web Developer    \n",
       "30                                   Order Processor    \n",
       "31                              Full Stack Developer    \n",
       "32                      Associate Software Developer    \n",
       "33                                 Reactjs Developer    \n",
       "34                              Full Stack Developer    \n",
       "35                    Business Development Executive    \n",
       "36                         Corporate Sales Associate    \n",
       "37                            Inside Sales Associate    \n",
       "38                              Mobile App Developer    \n",
       "39                       Junior MERN Stack Developer    \n",
       "40                      Education Innovation Manager    \n",
       "\n",
       "                                      Company_Names             CTC  \\\n",
       "1                                        Global Sun     3 - 3.2 LPA   \n",
       "2                Radish Consultants Private Limited       3 - 5 LPA   \n",
       "3         Medico Healthcare Services & Technologies     3 - 3.2 LPA   \n",
       "4                                         Edupixels           3 LPA   \n",
       "5                 Manufac Analytics Private Limited       3 - 4 LPA   \n",
       "6                                  Swabhav Techlabs     3 - 3.5 LPA   \n",
       "7                 Claraeon Learning Private Limited           3 LPA   \n",
       "8                                         Picostone     3 - 6.5 LPA   \n",
       "9                    AIMonk Labs Technology Limited       6 - 7 LPA   \n",
       "10                                  369 Zoss Waters       3 - 5 LPA   \n",
       "11                                     SleekSky LLC           4 LPA   \n",
       "12                       InPhase Power Technologies     3 - 3.5 LPA   \n",
       "13            Cactus Communications Private Limited       3 - 4 LPA   \n",
       "14                                StrategyCo.Global     4.5 - 7 LPA   \n",
       "15                        DataVinci Private Limited    4.99 - 5 LPA   \n",
       "16                                   The Test Tribe       3 - 4 LPA   \n",
       "17                                      Glu Studios     3 - 3.6 LPA   \n",
       "18                       Graygraph Technologies LLC     3 - 4.5 LPA   \n",
       "19                              BookLeaf Publishing     3 - 3.6 LPA   \n",
       "20                                  Ravi Ladia & Co           3 LPA   \n",
       "21                  Market Vistas Consumer Insights    3 - 3.25 LPA   \n",
       "22                        Global Source Trading LLC           3 LPA   \n",
       "23                             Blue Rose Publishers     3 - 3.5 LPA   \n",
       "24                            Best Roadways Limited           3 LPA   \n",
       "25                                         Geekster     3 - 3.5 LPA   \n",
       "26                InfyBytes AI Labs Private Limited       3 - 4 LPA   \n",
       "27                                        Moxie.xyz           9 LPA   \n",
       "28                                          GREedge        3.75 LPA   \n",
       "29                   Fullmoon Outdoor Web Solutions     4 - 4.2 LPA   \n",
       "30                                       InspectHOA           3 LPA   \n",
       "31            Nikulsan Technologies Private Limited     3.5 - 5 LPA   \n",
       "32                                        IQGateway    3.6 - 10 LPA   \n",
       "33          Startxlabs Technologies Private Limited       3 - 4 LPA   \n",
       "34  RavGins International Private Limited (Wobb.ai)     3.3 - 4 LPA   \n",
       "35                              Varenyam Placements       3 - 4 LPA   \n",
       "36          HealthPlix Technologies Private Limited       3 - 4 LPA   \n",
       "37                                 Wizklub Learning       3 - 6 LPA   \n",
       "38                               Fusion Engineering  4.5 - 5.25 LPA   \n",
       "39     DeepThought Edutech Ventures Private Limited       3 - 5 LPA   \n",
       "40     DeepThought Edutech Ventures Private Limited       3 - 5 LPA   \n",
       "\n",
       "    Apply_Date  \n",
       "1   21 Jul' 21  \n",
       "2   21 Jul' 21  \n",
       "3   21 Jul' 21  \n",
       "4   21 Jul' 21  \n",
       "5   19 Jul' 21  \n",
       "6   19 Jul' 21  \n",
       "7   19 Jul' 21  \n",
       "8   19 Jul' 21  \n",
       "9   18 Jul' 21  \n",
       "10  18 Jul' 21  \n",
       "11  18 Jul' 21  \n",
       "12  18 Jul' 21  \n",
       "13  18 Jul' 21  \n",
       "14  18 Jul' 21  \n",
       "15  17 Jul' 21  \n",
       "16  17 Jul' 21  \n",
       "17  17 Jul' 21  \n",
       "18  17 Jul' 21  \n",
       "19  17 Jul' 21  \n",
       "20  16 Jul' 21  \n",
       "21  17 Jul' 21  \n",
       "22  16 Jul' 21  \n",
       "23  16 Jul' 21  \n",
       "24  17 Jul' 21  \n",
       "25  16 Jul' 21  \n",
       "26  16 Jul' 21  \n",
       "27  15 Jul' 21  \n",
       "28  15 Jul' 21  \n",
       "29  15 Jul' 21  \n",
       "30  14 Jul' 21  \n",
       "31  14 Jul' 21  \n",
       "32  11 Jul' 21  \n",
       "33  11 Jul' 21  \n",
       "34  11 Jul' 21  \n",
       "35  11 Jul' 21  \n",
       "36  11 Jul' 21  \n",
       "37  11 Jul' 21  \n",
       "38  14 Jul' 21  \n",
       "39  15 Jul' 21  \n",
       "40  10 Jul' 21  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#9. Write a python program to scrape fresher job listings from ‘https://internshala.com/’. It should include job title, \n",
    "#company name, CTC, and apply date.\n",
    "\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "def getdata(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    titles=[]\n",
    "    comps=[]\n",
    "    ctcs=[]\n",
    "    applys=[]\n",
    "    for i in soup.find_all('div',class_=\"heading_4_5 profile\"):titles.append(i.text.replace('\\n',''))\n",
    "    for i in soup.find_all('a',class_=\"link_display_like_text\"):comps.append(i.text.strip())\n",
    "    for i in soup.find_all('div',class_=\"item_body\"): applys.append(i.text.strip())\n",
    "    ctcs=[applys[i] for i in range(1,len(applys),3)]\n",
    "    results=[applys[i] for i in range(2,len(applys),3)]\n",
    "    df=pd.DataFrame({'Job_Title':titles,\n",
    "                     'Company_Names':comps,\n",
    "                     'CTC':ctcs,'Apply_Date':results})\n",
    "    df = df.rename(index = lambda x: x+1)\n",
    "    return df   \n",
    "getdata('https://internshala.com/fresher-jobs/page-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>House_Title</th>\n",
       "      <th>Locations</th>\n",
       "      <th>Area</th>\n",
       "      <th>EMI</th>\n",
       "      <th>Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Nagan...</td>\n",
       "      <td>Independent House, Doddanagamangala Rd opposit...</td>\n",
       "      <td>1,200 sqft</td>\n",
       "      <td>45,851/Month</td>\n",
       "      <td>80 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4 BHK For Sale  In Daadys Garden In Electronic...</td>\n",
       "      <td>Daadys GardenÂ  Kammasandra Rd, Kammasandra, E...</td>\n",
       "      <td>2,600 sqft</td>\n",
       "      <td>85,971/Month</td>\n",
       "      <td>1.5 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Sarja...</td>\n",
       "      <td>Independent House,  Shantipura Village , S.P L...</td>\n",
       "      <td>1,100 sqft</td>\n",
       "      <td>40,120/Month</td>\n",
       "      <td>70 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4 BHK Flat  For Sale  In Electronic City</td>\n",
       "      <td>Standalone Building, Shikaripalya, near Shams ...</td>\n",
       "      <td>1,400 sqft</td>\n",
       "      <td>20,060/Month</td>\n",
       "      <td>35 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Elect...</td>\n",
       "      <td>Independent House,  Krishna reddy layout-Near ...</td>\n",
       "      <td>2,500 sqft</td>\n",
       "      <td>1.43 Lacs/Month</td>\n",
       "      <td>2.5 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Elect...</td>\n",
       "      <td>Independent House, Dhruv Dhama LayoutNear Hedd...</td>\n",
       "      <td>2,400 sqft</td>\n",
       "      <td>51,583/Month</td>\n",
       "      <td>90 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4 BHK Apartment  For Sale  In Gopalan Gardenia...</td>\n",
       "      <td>Gopalan GardeniaÂ  Gopalan gardenia, Veerasand...</td>\n",
       "      <td>2,650 sqft</td>\n",
       "      <td>63,045/Month</td>\n",
       "      <td>1.1 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4 BHK Flat  For Sale  In Electronic City</td>\n",
       "      <td>Standalone Building, Konappana Agrahara, Near ...</td>\n",
       "      <td>1,120 sqft</td>\n",
       "      <td>28,657/Month</td>\n",
       "      <td>50 Lacs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>4 BHK Flat  For Sale  In Heena Enclave In Elec...</td>\n",
       "      <td>Neeladri Nagar,Near Pioneer Sun Blossom</td>\n",
       "      <td>2,350 sqft</td>\n",
       "      <td>71,643/Month</td>\n",
       "      <td>1.25 Crores</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>4 BHK In Independent House  For Sale  In Anant...</td>\n",
       "      <td>Independent House, Glass factory Outlet nd cro...</td>\n",
       "      <td>2,200 sqft</td>\n",
       "      <td>56,168/Month</td>\n",
       "      <td>98 Lacs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          House_Title  \\\n",
       "1   4 BHK In Independent House  For Sale  In Nagan...   \n",
       "2   4 BHK For Sale  In Daadys Garden In Electronic...   \n",
       "3   4 BHK In Independent House  For Sale  In Sarja...   \n",
       "4           4 BHK Flat  For Sale  In Electronic City    \n",
       "5   4 BHK In Independent House  For Sale  In Elect...   \n",
       "6   4 BHK In Independent House  For Sale  In Elect...   \n",
       "7   4 BHK Apartment  For Sale  In Gopalan Gardenia...   \n",
       "8           4 BHK Flat  For Sale  In Electronic City    \n",
       "9   4 BHK Flat  For Sale  In Heena Enclave In Elec...   \n",
       "10  4 BHK In Independent House  For Sale  In Anant...   \n",
       "\n",
       "                                            Locations        Area  \\\n",
       "1   Independent House, Doddanagamangala Rd opposit...  1,200 sqft   \n",
       "2   Daadys GardenÂ  Kammasandra Rd, Kammasandra, E...  2,600 sqft   \n",
       "3   Independent House,  Shantipura Village , S.P L...  1,100 sqft   \n",
       "4   Standalone Building, Shikaripalya, near Shams ...  1,400 sqft   \n",
       "5   Independent House,  Krishna reddy layout-Near ...  2,500 sqft   \n",
       "6   Independent House, Dhruv Dhama LayoutNear Hedd...  2,400 sqft   \n",
       "7   Gopalan GardeniaÂ  Gopalan gardenia, Veerasand...  2,650 sqft   \n",
       "8   Standalone Building, Konappana Agrahara, Near ...  1,120 sqft   \n",
       "9             Neeladri Nagar,Near Pioneer Sun Blossom  2,350 sqft   \n",
       "10  Independent House, Glass factory Outlet nd cro...  2,200 sqft   \n",
       "\n",
       "                EMI         Cost  \n",
       "1      45,851/Month      80 Lacs  \n",
       "2      85,971/Month   1.5 Crores  \n",
       "3      40,120/Month      70 Lacs  \n",
       "4      20,060/Month      35 Lacs  \n",
       "5   1.43 Lacs/Month   2.5 Crores  \n",
       "6      51,583/Month      90 Lacs  \n",
       "7      63,045/Month   1.1 Crores  \n",
       "8      28,657/Month      50 Lacs  \n",
       "9      71,643/Month  1.25 Crores  \n",
       "10     56,168/Month      98 Lacs  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10. Write a python program to scrape house details from mentioned url. It should include house title, location, \n",
    "#area, emi and price\n",
    "#https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44NDUyMTQ1LC\n",
    "#Jsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHki\n",
    "#fV0=&propertyAge=0&radius=2.0\"\n",
    "\n",
    "#https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44NDUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0\n",
    "\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import pandas as pd\n",
    "def houseinfo(url):\n",
    "    page = requests.get(url)\n",
    "    soup = BeautifulSoup(page.text,'html.parser')\n",
    "    htitles=[]\n",
    "    locations=[]\n",
    "    allvalue=[] \n",
    "    areas=[] \n",
    "    emis=[]\n",
    "    prices=[]\n",
    "    for i in soup.find_all('h2',class_=\"heading-6 font-semi-bold nb__1AShY\"):htitles.append(i.text)\n",
    "    for i in soup.find_all(  'div',class_=\"nb__2CMjv\"): locations.append(i.text)\n",
    "    for i in soup.find_all('div',class_=\"font-semi-bold heading-6\"):allvalue.append(i.text.replace('â\\x82¹',''))\n",
    "    areas=allvalue[0:len(allvalue):3]\n",
    "    emis=allvalue[1:len(allvalue):3]\n",
    "    prices=allvalue[2:len(allvalue):3]\n",
    "    hdetails = pd.DataFrame({'House_Title':htitles,'Locations':locations,'Area':areas,'EMI':emis,'Cost':prices})\n",
    "    hdetails = hdetails.rename(index = lambda x: x+1)\n",
    "    return hdetails \n",
    "houseinfo('https://www.nobroker.in/property/sale/bangalore/Electronic%20City?type=BHK4&searchParam=W3sibGF0IjoxMi44NDUyMTQ1LCJsb24iOjc3LjY2MDE2OTUsInBsYWNlSWQiOiJDaElKdy1GUWQ0cHNyanNSSGZkYXpnXzhYRW8iLCJwbGFjZU5hbWUiOiJFbGVjdHJvbmljIENpdHkifV0=&propertyAge=0&radius=2.0')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
